{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we perform benchmark on selected libraries for generating long text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-12-30T10:48:39.715675Z",
     "iopub.status.busy": "2024-12-30T10:48:39.715371Z",
     "iopub.status.idle": "2024-12-30T10:48:44.792977Z",
     "shell.execute_reply": "2024-12-30T10:48:44.792122Z",
     "shell.execute_reply.started": "2024-12-30T10:48:39.715648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "#install important libraries\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-30T10:48:44.794144Z",
     "iopub.status.busy": "2024-12-30T10:48:44.793893Z",
     "iopub.status.idle": "2024-12-30T10:49:00.898801Z",
     "shell.execute_reply": "2024-12-30T10:49:00.897842Z",
     "shell.execute_reply.started": "2024-12-30T10:48:44.794124Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text  \n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import models\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding normalization for computing simmilarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:00.900305Z",
     "iopub.status.busy": "2024-12-30T10:49:00.899722Z",
     "iopub.status.idle": "2024-12-30T10:49:00.904223Z",
     "shell.execute_reply": "2024-12-30T10:49:00.903513Z",
     "shell.execute_reply.started": "2024-12-30T10:49:00.900281Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalization(embeds):\n",
    "  '''\n",
    "  Normalizes sentence embeddings.\n",
    "  '''\n",
    "  norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n",
    "  return embeds/norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLS pooling for transformer models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:00.905679Z",
     "iopub.status.busy": "2024-12-30T10:49:00.905368Z",
     "iopub.status.idle": "2024-12-30T10:49:00.922497Z",
     "shell.execute_reply": "2024-12-30T10:49:00.921841Z",
     "shell.execute_reply.started": "2024-12-30T10:49:00.905651Z"
    }
   },
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    '''\n",
    "    Performs cls pooling on model output\n",
    "    '''\n",
    "    return model_output[0][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shortening decimal places for easily-readable output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:00.923749Z",
     "iopub.status.busy": "2024-12-30T10:49:00.923432Z",
     "iopub.status.idle": "2024-12-30T10:49:00.937188Z",
     "shell.execute_reply": "2024-12-30T10:49:00.936533Z",
     "shell.execute_reply.started": "2024-12-30T10:49:00.923720Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_short(x):\n",
    "    '''\n",
    "    Shortens float value to two decimal places\n",
    "    '''\n",
    "    return f\"{x:.2f}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of benchmark datasets and perform data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUCC Dataset import & analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:00.940031Z",
     "iopub.status.busy": "2024-12-30T10:49:00.939820Z",
     "iopub.status.idle": "2024-12-30T10:49:02.710104Z",
     "shell.execute_reply": "2024-12-30T10:49:02.709401Z",
     "shell.execute_reply.started": "2024-12-30T10:49:00.940015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6b016c0ffa4654a3c1a3cbe83f7d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a719877293442989cc61bd5dd4d381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en.jsonl.gz:   0%|          | 0.00/834k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a0b566ad0c437ba618cf12b1e56230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fr-en.jsonl.gz:   0%|          | 0.00/713k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c208c8dc6ccb4d00b595ba1507624ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru-en.jsonl.gz:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa8e0456d9041d9bd27b196a0cf39bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "zh-en.jsonl.gz:   0%|          | 0.00/181k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8499ab271ed49d2b5751974102bbd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bucc_ds = load_dataset(\"mteb/bucc-bitext-mining\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.711796Z",
     "iopub.status.busy": "2024-12-30T10:49:02.711583Z",
     "iopub.status.idle": "2024-12-30T10:49:02.716969Z",
     "shell.execute_reply": "2024-12-30T10:49:02.716101Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.711778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'lang'],\n",
       "        num_rows: 35000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a pandas DataFrame out of dataset for easier manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.718231Z",
     "iopub.status.busy": "2024-12-30T10:49:02.718012Z",
     "iopub.status.idle": "2024-12-30T10:49:02.872435Z",
     "shell.execute_reply": "2024-12-30T10:49:02.871776Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.718203Z"
    }
   },
   "outputs": [],
   "source": [
    "bucc_df = pd.DataFrame()\n",
    "for k in bucc_ds['test'].features.keys():\n",
    "    bucc_df[k] =  bucc_ds['test'][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.873414Z",
     "iopub.status.busy": "2024-12-30T10:49:02.873159Z",
     "iopub.status.idle": "2024-12-30T10:49:02.877887Z",
     "shell.execute_reply": "2024-12-30T10:49:02.877186Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.873393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bucc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for empty columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.879069Z",
     "iopub.status.busy": "2024-12-30T10:49:02.878787Z",
     "iopub.status.idle": "2024-12-30T10:49:02.900120Z",
     "shell.execute_reply": "2024-12-30T10:49:02.899417Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.879040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "for col in bucc_df.columns:\n",
    "    print(pd.isnull(bucc_df[col]).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that the dataset has 5 different languages, from all of which we are going to use for experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.901232Z",
     "iopub.status.busy": "2024-12-30T10:49:02.900947Z",
     "iopub.status.idle": "2024-12-30T10:49:02.921709Z",
     "shell.execute_reply": "2024-12-30T10:49:02.920729Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.901204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "ru-en    14435\n",
       "de-en     9580\n",
       "fr-en     9086\n",
       "zh-en     1899\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucc_df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing benchmarks on BUCC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries for generating embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.922979Z",
     "iopub.status.busy": "2024-12-30T10:49:02.922659Z",
     "iopub.status.idle": "2024-12-30T10:49:02.932134Z",
     "shell.execute_reply": "2024-12-30T10:49:02.931394Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.922947Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['microsoft/infoxlm-base', \n",
    "          'LaBSE',\n",
    "          'mUSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all examined libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:02.933134Z",
     "iopub.status.busy": "2024-12-30T10:49:02.932891Z",
     "iopub.status.idle": "2024-12-30T10:49:22.924910Z",
     "shell.execute_reply": "2024-12-30T10:49:22.924200Z",
     "shell.execute_reply.started": "2024-12-30T10:49:02.933103Z"
    }
   },
   "outputs": [],
   "source": [
    "labse_preprocessor = hub.KerasLayer(\n",
    "    \"https://kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/cmlm-multilingual-preprocess/2\")\n",
    "labse_encoder = hub.KerasLayer(\"https://www.kaggle.com/models/google/labse/TensorFlow2/labse/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import models from huggingface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:22.926068Z",
     "iopub.status.busy": "2024-12-30T10:49:22.925759Z",
     "iopub.status.idle": "2024-12-30T10:49:32.566281Z",
     "shell.execute_reply": "2024-12-30T10:49:32.565560Z",
     "shell.execute_reply.started": "2024-12-30T10:49:22.926040Z"
    }
   },
   "outputs": [],
   "source": [
    "mUSE = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/multilingual-large/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:32.567560Z",
     "iopub.status.busy": "2024-12-30T10:49:32.567222Z",
     "iopub.status.idle": "2024-12-30T10:49:40.744662Z",
     "shell.execute_reply": "2024-12-30T10:49:40.743959Z",
     "shell.execute_reply.started": "2024-12-30T10:49:32.567518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7efa89431a4dec88d90c3ec0cff952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/512 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e164a1ca584b0d8fad67f538208ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36642e07aa134e3ea9f5bfc57e753282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d383055214c698a78921b27bbb0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/942M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlmb_tknzr = AutoTokenizer.from_pretrained('microsoft/infoxlm-base')\n",
    "xlmb_mdl = AutoModel.from_pretrained('microsoft/infoxlm-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.745861Z",
     "iopub.status.busy": "2024-12-30T10:49:40.745535Z",
     "iopub.status.idle": "2024-12-30T10:49:40.750174Z",
     "shell.execute_reply": "2024-12-30T10:49:40.749385Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.745828Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep_res_df(input_df:pd.DataFrame)->pd.DataFrame:\n",
    "    '''\n",
    "    Creates result dataframe for experiments\n",
    "    \n",
    "    input_df\n",
    "    --------\n",
    "        pd.DataFrame that provides columns for result dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame Empty dataframe that uses the same column with extra column for model.\n",
    "    '''\n",
    "    a = ['model'] \n",
    "    b = input_df['lang'].unique()\n",
    "    cols = [*a, *b]\n",
    "    \n",
    "    return pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.751154Z",
     "iopub.status.busy": "2024-12-30T10:49:40.750886Z",
     "iopub.status.idle": "2024-12-30T10:49:40.768336Z",
     "shell.execute_reply": "2024-12-30T10:49:40.767701Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.751127Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = bucc_df['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants that define the comparing environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.769187Z",
     "iopub.status.busy": "2024-12-30T10:49:40.769010Z",
     "iopub.status.idle": "2024-12-30T10:49:40.784575Z",
     "shell.execute_reply": "2024-12-30T10:49:40.783980Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.769171Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we define functions for working with different models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.785314Z",
     "iopub.status.busy": "2024-12-30T10:49:40.785133Z",
     "iopub.status.idle": "2024-12-30T10:49:40.795312Z",
     "shell.execute_reply": "2024-12-30T10:49:40.794610Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.785298Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_embd(model:AutoModel,tokenizer:AutoTokenizer,new_snts:list,eng_snts:list)->float:\n",
    "    '''\n",
    "    This function is used for evaluating XLM model.\n",
    "    It computes embedding of provided sentences and compare them with English counterparts.\n",
    "    Then computes average accuracy based on cosine similarity over batches.\n",
    "\n",
    "    model\n",
    "    -----\n",
    "\n",
    "    new_snts\n",
    "    --------\n",
    "        list of sentences in one of the supported languages\n",
    "    eng_snts\n",
    "    --------\n",
    "        list of sentences in english to be compared with\n",
    "    Returns\n",
    "    -------\n",
    "        float, average accuracy among all batches \n",
    "    '''\n",
    "    acc = []\n",
    "    for i in range(0, len(new_snts), batch_size):\n",
    "        new_snts_b = new_snts[i:i + batch_size]\n",
    "        eng_snts_b = eng_snts[i:i + batch_size]\n",
    "        \n",
    "        real = [i for i in range(0,len(eng_snts_b))]\n",
    "       \n",
    "        model = model.to(device)\n",
    "        \n",
    "        new_encoded = tokenizer(new_snts_b, padding=True,  return_tensors='pt').to(device)\n",
    "        eng_encoded = tokenizer(eng_snts_b,padding=True, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ot_new = model(**new_encoded)\n",
    "            ot_eng = model(**eng_encoded)\n",
    "    \n",
    "        new_embd = cls_pooling(ot_new ).cpu()\n",
    "        eng_embd = cls_pooling(ot_eng).cpu()\n",
    "    \n",
    "    \n",
    "        sim_mtx= similarity_matrix = cosine_similarity(new_embd.numpy(), eng_embd.numpy())\n",
    "        \n",
    "        retrieved_indices = np.argmax(sim_mtx, axis=1)\n",
    "        acc.append(round(accuracy_score(real,retrieved_indices),2))\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.798610Z",
     "iopub.status.busy": "2024-12-30T10:49:40.798313Z",
     "iopub.status.idle": "2024-12-30T10:49:40.813548Z",
     "shell.execute_reply": "2024-12-30T10:49:40.812845Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.798578Z"
    }
   },
   "outputs": [],
   "source": [
    "def labs_embd(new_snts:list,eng_snts:list)->float:\n",
    "    '''\n",
    "    This function is used for evaluating LaBSe model.\n",
    "    It computes embedding of provided sentences and compare them with English counterparts.\n",
    "    Then computes average accuracy based on cosine similarity over batches.\n",
    "\n",
    "    new_snts\n",
    "    --------\n",
    "        list of sentences in one of the supported languages\n",
    "    eng_snts\n",
    "    --------\n",
    "        list of sentences in english to be compared with\n",
    "    Returns\n",
    "    -------\n",
    "        float, average accuracy among all batches \n",
    "\n",
    "    '''\n",
    "    \n",
    "    acc = []\n",
    "    for i in range(0, len(new_snts), batch_size):\n",
    "        #print(\"batch \" + str(i))\n",
    "        new_snts_b = new_snts[i:i + batch_size]\n",
    "        eng_snts_b = eng_snts[i:i + batch_size]\n",
    "        real = [i for i in range(0,len(eng_snts_b))]\n",
    "        \n",
    "        new_snts_b = tf.constant(new_snts_b)\n",
    "        eng_snts_b = tf.constant(eng_snts_b)\n",
    "\n",
    "    \n",
    "        new_embeds = normalization(labse_encoder(labse_preprocessor(new_snts_b))['default'])\n",
    "        \n",
    "        \n",
    "        eng_embeds = normalization(labse_encoder(labse_preprocessor(eng_snts_b))[\"default\"])\n",
    "        #print(\"embs 2 done\")\n",
    "        similarity_matrix = cosine_similarity(new_embeds.numpy(), eng_embeds.cpu().numpy())\n",
    "        retrieved_indices = np.argmax(similarity_matrix, axis=1)\n",
    "        acc.append(round(accuracy_score(real,retrieved_indices),2))\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.815293Z",
     "iopub.status.busy": "2024-12-30T10:49:40.815084Z",
     "iopub.status.idle": "2024-12-30T10:49:40.829987Z",
     "shell.execute_reply": "2024-12-30T10:49:40.829156Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.815276Z"
    }
   },
   "outputs": [],
   "source": [
    "def mUSE_embd(new_snts:list,eng_snts:list)->float:\n",
    "    '''\n",
    "    This function is used for evaluating mUSE model.\n",
    "    It computes embedding of provided sentences and compare them with English counterparts.\n",
    "    Then computes average accuracy based on cosine similarity over batches.\n",
    "\n",
    "    new_snts\n",
    "    --------\n",
    "        list of sentences in one of the supported languages\n",
    "    eng_snts\n",
    "    --------\n",
    "        list of sentences in english to be compared with\n",
    "    Returns\n",
    "    -------\n",
    "        float, average accuracy among all batches \n",
    "\n",
    "    '''\n",
    "    acc = []\n",
    "    for i in range(0, len(new_snts), batch_size):\n",
    "        new_snts_b = new_snts[i:i + batch_size]\n",
    "        eng_snts_b = eng_snts[i:i + batch_size]\n",
    "        real = [i for i in range(0,len(eng_snts_b))]\n",
    "        new_snts_b = tf.constant(new_snts_b)\n",
    "        eng_snts_b = tf.constant(eng_snts_b)\n",
    "\n",
    "        new_embeds = mUSE(new_snts_b)\n",
    "        eng_embeds = mUSE(eng_snts_b)\n",
    "        similarity_matrix = cosine_similarity(new_embeds.numpy(), eng_embeds.cpu().numpy())\n",
    "        retrieved_indices = np.argmax(similarity_matrix, axis=1)\n",
    "        acc.append(round(accuracy_score(real,retrieved_indices),2))\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.831092Z",
     "iopub.status.busy": "2024-12-30T10:49:40.830815Z",
     "iopub.status.idle": "2024-12-30T10:49:40.846973Z",
     "shell.execute_reply": "2024-12-30T10:49:40.846188Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.831064Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_experiments(models:list, in_df:pd.DataFrame, langs:list)->pd.DataFrame:\n",
    "    '''\n",
    "    Performs experiment with given dataset on all provided modes and languages.\n",
    "    Computes average accuracy for all of the languages and save it to dataframe.\n",
    "\n",
    "    models\n",
    "    ------\n",
    "        list of models that are used for benchmarks\n",
    "    in_df\n",
    "    -----\n",
    "        pandas.DataFrame that stores texts in all provided languages\n",
    "    langs\n",
    "    -----\n",
    "        list of languages that are used in benchmarks\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pandas.DataFrame of results\n",
    "\n",
    "    \n",
    "    '''\n",
    "\n",
    "    res_df = prep_res_df(in_df)\n",
    "    size=20000\n",
    "    for idx,m in enumerate(models):\n",
    "        \n",
    "        acc = []\n",
    "        acc.append(m)\n",
    "\n",
    "        \n",
    "        for l in langs:\n",
    "            new_df = in_df[in_df['lang'] == l]\n",
    "            new_size = size if len(new_df) > size else len(new_df)\n",
    "            new_snts = list(new_df['sentence1'].head(new_size))\n",
    "            eng_snts = list(new_df['sentence2'].head(new_size))\n",
    "           \n",
    "            if m == \"LaBSE\":\n",
    "                res = labs_embd(new_snts,eng_snts)\n",
    "                acc.append(res)\n",
    "                          \n",
    "            if m == 'microsoft/infoxlm-base':\n",
    "                res = model_embd(xlmb_mdl,xlmb_tknzr,new_snts,eng_snts)\n",
    "                acc.append(res)\n",
    "            if m == 'mUSE':\n",
    "                res = mUSE_embd(new_snts,eng_snts)\n",
    "                acc.append(res)\n",
    "           \n",
    "        print(acc)\n",
    "        res_df.loc[len(res_df)] = acc\n",
    "    res_df = res_df.set_index('model')\n",
    "    return res_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.848193Z",
     "iopub.status.busy": "2024-12-30T10:49:40.847913Z",
     "iopub.status.idle": "2024-12-30T10:49:40.864278Z",
     "shell.execute_reply": "2024-12-30T10:49:40.863403Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.848165Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_res(latex_table:str,name)->None:\n",
    "    '''\n",
    "    Saves the results to latex table\n",
    "    latex_table\n",
    "    -----------\n",
    "        string that defines created latex table\n",
    "    name\n",
    "    ----\n",
    "        string that defines the name of the file\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    with open(name+ '.txt','w+') as f:\n",
    "        f.write(latex_table)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.865383Z",
     "iopub.status.busy": "2024-12-30T10:49:40.865095Z",
     "iopub.status.idle": "2024-12-30T10:49:40.878791Z",
     "shell.execute_reply": "2024-12-30T10:49:40.878024Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.865355Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = perform_experiments(models, bucc_df,langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.879732Z",
     "iopub.status.busy": "2024-12-30T10:49:40.879526Z",
     "iopub.status.idle": "2024-12-30T10:49:40.891992Z",
     "shell.execute_reply": "2024-12-30T10:49:40.891278Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.879715Z"
    }
   },
   "outputs": [],
   "source": [
    "latex_table = res_df.style.format({\n",
    "        \"de-en\": to_short,\n",
    "        \"fr-en\": to_short,\n",
    "        \"ru-en\": to_short,\n",
    "        \"zh-en\":to_short\n",
    "        }).to_latex()\n",
    "latex_table = latex_table.replace('{lrrrr}', '{l||c|c|c|c}')\n",
    "latex_table = latex_table.replace('model &  &  &  &  \\\\\\\\', '\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.893113Z",
     "iopub.status.busy": "2024-12-30T10:49:40.892833Z",
     "iopub.status.idle": "2024-12-30T10:49:40.907510Z",
     "shell.execute_reply": "2024-12-30T10:49:40.906732Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.893086Z"
    }
   },
   "outputs": [],
   "source": [
    "save_res(latex_table,'bucc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tatoeba dataset import and analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.908409Z",
     "iopub.status.busy": "2024-12-30T10:49:40.908221Z",
     "iopub.status.idle": "2024-12-30T10:49:40.920552Z",
     "shell.execute_reply": "2024-12-30T10:49:40.919842Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.908393Z"
    }
   },
   "outputs": [],
   "source": [
    "tatoeba_pairs = [('en','fr'),('en','ru'),('de','en'),('cs','en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.921436Z",
     "iopub.status.busy": "2024-12-30T10:49:40.921189Z",
     "iopub.status.idle": "2024-12-30T10:49:40.935923Z",
     "shell.execute_reply": "2024-12-30T10:49:40.935273Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.921417Z"
    }
   },
   "outputs": [],
   "source": [
    "def crt_tat_df(tatoeba_pairs)->pd.DataFrame:\n",
    "    new_df = pd.DataFrame(columns=['sentence1','sentence2','lang'])\n",
    "    for p in tatoeba_pairs:\n",
    "        dataset = load_dataset(\"tatoeba\",lang1=p[0], lang2=p[1],split= 'train',trust_remote_code=True)\n",
    "        size = 200 if p[0] != 'cs' else 100\n",
    "        e_idx = 0 if p[0] == 'en' else 1 \n",
    "        n_idx = e_idx-1 % 2\n",
    "        n_eng = p[n_idx]\n",
    "        \n",
    "        \n",
    "        for d in dataset['translation']:\n",
    "            if len(d[p[0]]) + len(d[p[1]]) > size:\n",
    "                new_df.loc[len(new_df) ] = [d[p[n_idx]],d[p[e_idx]],n_eng]\n",
    "                \n",
    "                \n",
    "    return new_df     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.937002Z",
     "iopub.status.busy": "2024-12-30T10:49:40.936734Z",
     "iopub.status.idle": "2024-12-30T10:49:40.949543Z",
     "shell.execute_reply": "2024-12-30T10:49:40.948830Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.936982Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:49:40.950341Z",
     "iopub.status.busy": "2024-12-30T10:49:40.950161Z",
     "iopub.status.idle": "2024-12-30T10:50:46.217080Z",
     "shell.execute_reply": "2024-12-30T10:50:46.216167Z",
     "shell.execute_reply.started": "2024-12-30T10:49:40.950325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abdb6c5d4e640398a1fcc0418cd9c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898396deeed4480e8085a7775b54a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tatoeba.py:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37b88ccb6bb4407bf9433249ed90589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740850344ab94b6cbcc4259dd7d5b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd0ec0c8b0843e0a77fc9168977106c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71eae5520aa847179ee47546196b25a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b462a839e945668173ff8282660d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.88M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad0c219fc7f4d1e97691f8ad8eed891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca53c1541f7642779ca3d305f6cfb9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/944k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dc355aed7946feb9dae428a8cdbbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tat_df = crt_tat_df(tatoeba_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:50:46.218342Z",
     "iopub.status.busy": "2024-12-30T10:50:46.218029Z",
     "iopub.status.idle": "2024-12-30T10:50:46.225401Z",
     "shell.execute_reply": "2024-12-30T10:50:46.224561Z",
     "shell.execute_reply.started": "2024-12-30T10:50:46.218300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "de    5017\n",
       "fr    3469\n",
       "ru    2598\n",
       "cs    2226\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tat_df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:50:46.226464Z",
     "iopub.status.busy": "2024-12-30T10:50:46.226261Z",
     "iopub.status.idle": "2024-12-30T10:50:46.241250Z",
     "shell.execute_reply": "2024-12-30T10:50:46.240433Z",
     "shell.execute_reply.started": "2024-12-30T10:50:46.226446Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = list(tat_df['lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T10:50:46.242325Z",
     "iopub.status.busy": "2024-12-30T10:50:46.242065Z",
     "iopub.status.idle": "2024-12-30T10:50:46.256700Z",
     "shell.execute_reply": "2024-12-30T10:50:46.255843Z",
     "shell.execute_reply.started": "2024-12-30T10:50:46.242306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fr', 'ru', 'de', 'cs']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we perform experiments with Tatoeba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-30T10:51:22.000Z",
     "iopub.execute_input": "2024-12-30T10:50:46.257924Z",
     "iopub.status.busy": "2024-12-30T10:50:46.257582Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = perform_experiments(models, tat_df, langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-30T10:51:22.000Z"
    }
   },
   "outputs": [],
   "source": [
    "latex_table = res_df.style.format({\n",
    "        \"fr\": to_short,\n",
    "        \"ru\": to_short,\n",
    "        \"de\": to_short,\n",
    "        \"cs\":to_short\n",
    "        }).to_latex()\n",
    "latex_table = latex_table.replace('{lrrrr}', '{l||c|c|c|c}')\n",
    "latex_table = latex_table.replace('model &  &  &  &  \\\\\\\\', '\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-30T10:51:22.000Z"
    }
   },
   "outputs": [],
   "source": [
    "save_res(latex_table,'tatoeba')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelId": 129,
     "modelInstanceId": 981,
     "sourceId": 1135,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 191,
     "modelInstanceId": 1283,
     "sourceId": 1523,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 191,
     "modelInstanceId": 1286,
     "sourceId": 1527,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
