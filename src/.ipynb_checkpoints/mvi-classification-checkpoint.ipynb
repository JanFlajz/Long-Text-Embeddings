{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this notebook is to use examined libraries for text embedding generation in a text classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:22.122290Z",
     "iopub.status.busy": "2024-12-31T10:17:22.122055Z",
     "iopub.status.idle": "2024-12-31T10:17:27.398894Z",
     "shell.execute_reply": "2024-12-31T10:17:27.397768Z",
     "shell.execute_reply.started": "2024-12-31T10:17:22.122262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:27.400637Z",
     "iopub.status.busy": "2024-12-31T10:17:27.400228Z",
     "iopub.status.idle": "2024-12-31T10:17:42.581920Z",
     "shell.execute_reply": "2024-12-31T10:17:42.581192Z",
     "shell.execute_reply.started": "2024-12-31T10:17:27.400590Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import models\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error,f1_score\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from datasets import load_dataset\n",
    "import torch.amp\n",
    "import torch.optim\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text  \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch.amp\n",
    "import torch.optim\n",
    "from huggingface_hub.utils import are_progress_bars_disabled, disable_progress_bars, enable_progress_bars\n",
    "disable_progress_bars()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:42.583308Z",
     "iopub.status.busy": "2024-12-31T10:17:42.582760Z",
     "iopub.status.idle": "2024-12-31T10:17:42.772305Z",
     "shell.execute_reply": "2024-12-31T10:17:42.771293Z",
     "shell.execute_reply.started": "2024-12-31T10:17:42.583280Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lng_final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets split data to train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:42.773755Z",
     "iopub.status.busy": "2024-12-31T10:17:42.773369Z",
     "iopub.status.idle": "2024-12-31T10:17:42.785116Z",
     "shell.execute_reply": "2024-12-31T10:17:42.784275Z",
     "shell.execute_reply.started": "2024-12-31T10:17:42.773709Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we load the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:42.786480Z",
     "iopub.status.busy": "2024-12-31T10:17:42.786193Z",
     "iopub.status.idle": "2024-12-31T10:17:42.797377Z",
     "shell.execute_reply": "2024-12-31T10:17:42.796637Z",
     "shell.execute_reply.started": "2024-12-31T10:17:42.786459Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['LaBSE',\n",
    "          'mUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:42.800300Z",
     "iopub.status.busy": "2024-12-31T10:17:42.800107Z",
     "iopub.status.idle": "2024-12-31T10:17:53.788424Z",
     "shell.execute_reply": "2024-12-31T10:17:53.787702Z",
     "shell.execute_reply.started": "2024-12-31T10:17:42.800283Z"
    }
   },
   "outputs": [],
   "source": [
    "mUSE = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/multilingual-large/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:17:53.790549Z",
     "iopub.status.busy": "2024-12-31T10:17:53.790195Z",
     "iopub.status.idle": "2024-12-31T10:18:05.999783Z",
     "shell.execute_reply": "2024-12-31T10:18:05.998963Z",
     "shell.execute_reply.started": "2024-12-31T10:17:53.790514Z"
    }
   },
   "outputs": [],
   "source": [
    "labse_mdl = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.000817Z",
     "iopub.status.busy": "2024-12-31T10:18:06.000583Z",
     "iopub.status.idle": "2024-12-31T10:18:06.007112Z",
     "shell.execute_reply": "2024-12-31T10:18:06.006042Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.000797Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    This class provides the dataset for the classification model.\n",
    "    '''\n",
    "    def __init__(self,  dataset:pd.DataFrame, tokenizer_name:str,text_col:str, label_col:str, sample=None):\n",
    "        texts = dataset\n",
    "        if sample:\n",
    "            texts = texts.sample(sample)\n",
    "        \n",
    "        \n",
    "        self.texts = texts[text_col].values.tolist()\n",
    "        self.labels = texts[label_col].values.tolist()\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = {}\n",
    "        res['text'] = self.texts[idx]\n",
    "        res['label'] = self.labels[idx]\n",
    "        return res\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.008319Z",
     "iopub.status.busy": "2024-12-31T10:18:06.008041Z",
     "iopub.status.idle": "2024-12-31T10:18:06.146741Z",
     "shell.execute_reply": "2024-12-31T10:18:06.145902Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.008289Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_text(m:str,text:list):\n",
    "    '''\n",
    "    Computes embedding for provided text\n",
    "\n",
    "    m\n",
    "    ----\n",
    "        string that defines the library\n",
    "    text\n",
    "    ----\n",
    "        list of texts for tokenization \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        pytroch.Tensor\n",
    "    '''\n",
    "    \n",
    "    if m == 'mUSE':\n",
    "        res = torch.Tensor(mUSE(tf.constant(text)).numpy())\n",
    "            \n",
    "    if m == 'LaBSE':\n",
    "        res = torch.Tensor(labse_mdl.encode(text, show_progress_bar=False))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.148049Z",
     "iopub.status.busy": "2024-12-31T10:18:06.147718Z",
     "iopub.status.idle": "2024-12-31T10:18:06.160680Z",
     "shell.execute_reply": "2024-12-31T10:18:06.159959Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.148016Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    '''\n",
    "    This class handels the classification model.\n",
    "    The model consists of one linear layer with dropout and one output layer.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,backbone:str,drop_out:float):\n",
    "        '''\n",
    "        The constructor defines the internal dimensions of the model and the inside layers.\n",
    "\n",
    "        backbone\n",
    "        --------\n",
    "            string that defines the name of the library which declares the in dimension\n",
    "        drop_out\n",
    "        -------\n",
    "            float that defines the dropout rate of dropout layer\n",
    "        '''\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dropout = drop_out\n",
    "        self.input_dim = 768 if backbone != 'mUSE' else 512\n",
    "        self.inner_dim = 64\n",
    "        self.output_dim = 3\n",
    "        \n",
    "        #layers\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.inner_dim)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(self.inner_dim, self.output_dim)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Passes the data trough the network\n",
    "        x\n",
    "        ----\n",
    "            input data\n",
    "        '''\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.161656Z",
     "iopub.status.busy": "2024-12-31T10:18:06.161416Z",
     "iopub.status.idle": "2024-12-31T10:18:06.178378Z",
     "shell.execute_reply": "2024-12-31T10:18:06.177442Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.161636Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(train_dl:DataLoader, model:CustomModel, loss_fn, optimizer, scheduler, device:str, m,log_every=1):\n",
    "    '''\n",
    "    Trains the model and performs backpropagation.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    losses = []\n",
    "    lr_values = []\n",
    "    size = len(train_dl)\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for batch_idx,batch in enumerate(train_dl):\n",
    "        x = batch['text']\n",
    "        y = batch['label'].to(device)\n",
    "        with torch.no_grad():  \n",
    "            x = embed_text(m,x).to(device)\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "\n",
    "            pred = model(x)   \n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        if batch_idx % log_every == 0:\n",
    "            losses.append(loss.detach().cpu().item())\n",
    "            lr_values.append(scheduler.get_lr()[0])\n",
    "\n",
    "        loss, current = loss.item(), (batch_idx + 1)\n",
    "        #pbar.set_description(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return losses, lr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.179901Z",
     "iopub.status.busy": "2024-12-31T10:18:06.179536Z",
     "iopub.status.idle": "2024-12-31T10:18:06.192382Z",
     "shell.execute_reply": "2024-12-31T10:18:06.191650Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.179862Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_loop(model:CustomModel, dataloader:DataLoader, device:str,m:str, **predict_kwargs):\n",
    "\n",
    "    '''\n",
    "    Performs the inference of the model\n",
    "    '''\n",
    "    \n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    model.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in dataloader:\n",
    "            x = batch['text']\n",
    "            y = batch['label'].to(device)  \n",
    "            x = embed_text(m,x).to(device)\n",
    "            \n",
    "            pred = model(x,  **predict_kwargs)\n",
    "            pred_lbls = torch.argmax(pred, dim=1)\n",
    "            predictions.extend(pred_lbls.cpu().tolist())\n",
    "            \n",
    "            if y is not None:\n",
    "                labels.extend(y.cpu().tolist())\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.193490Z",
     "iopub.status.busy": "2024-12-31T10:18:06.193195Z",
     "iopub.status.idle": "2024-12-31T10:18:06.203013Z",
     "shell.execute_reply": "2024-12-31T10:18:06.202282Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.193455Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation_loop(val_dl:DataLoader, model:CustomModel, val_metrics, device:str,m:str):\n",
    "    '''\n",
    "    Computes the validation score for the model.\n",
    "    \n",
    "    '''\n",
    "    predictions, labels = inference_loop(model, val_dl, device,m)\n",
    "    scores = {metric.__name__: metric(labels, predictions,average='micro') for metric in val_metrics}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.204139Z",
     "iopub.status.busy": "2024-12-31T10:18:06.203838Z",
     "iopub.status.idle": "2024-12-31T10:18:06.217023Z",
     "shell.execute_reply": "2024-12-31T10:18:06.216294Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.204116Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model : CustomModel, train_dl:DataLoader, val_dl:DataLoader, loss, optimizer, scheduler, epochs, val_metrics, device,m):\n",
    "    '''\n",
    "    Trains the model for all of the epochs and computes scores and losses. \n",
    "    '''\n",
    "    scores = []\n",
    "    losses = []\n",
    "    lr_rates = []\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\\n-------------------------------\")\n",
    "        epoch_losses, epoch_lr_rates = train_loop(train_dl, model, loss, optimizer, scheduler, device,m)\n",
    "        epoch_scores = validation_loop(val_dl, model, val_metrics, device,m)\n",
    "        print(epoch_scores)\n",
    "        print(f\"Loss {np.mean(epoch_losses)}\")\n",
    "        scores.append(epoch_scores)\n",
    "        losses.extend(epoch_losses)\n",
    "        lr_rates.extend(epoch_lr_rates)\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return model, scores, losses, lr_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.218212Z",
     "iopub.status.busy": "2024-12-31T10:18:06.217906Z",
     "iopub.status.idle": "2024-12-31T10:18:06.229063Z",
     "shell.execute_reply": "2024-12-31T10:18:06.228354Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.218184Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model:CustomModel, test_dl:DataLoader, device:str,m:str):\n",
    "    '''\n",
    "    Only predicts the classes provided the input data.\n",
    "    '''\n",
    "    model.to(device)\n",
    "    predictions, _ = inference_loop(model, test_dl, device,m)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.230112Z",
     "iopub.status.busy": "2024-12-31T10:18:06.229902Z",
     "iopub.status.idle": "2024-12-31T10:18:06.241321Z",
     "shell.execute_reply": "2024-12-31T10:18:06.240520Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.230093Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_only(model:CustomModel, train_dl:DataLoader, loss, optimizer, scheduler, epochs, val_metrics, device,m):\n",
    "    '''\n",
    "    Serves for final training on the whole dataset.\n",
    "    '''\n",
    "    scores = []\n",
    "    losses = []\n",
    "    lr_rates = []\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\\n-------------------------------\")\n",
    "        epoch_losses, epoch_lr_rates = train_loop(train_dl, model, loss, optimizer, scheduler, device,m)\n",
    "        print(f\"Loss {np.mean(epoch_losses)}\")\n",
    "        losses.extend(epoch_losses)\n",
    "        lr_rates.extend(epoch_lr_rates)\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.242401Z",
     "iopub.status.busy": "2024-12-31T10:18:06.242194Z",
     "iopub.status.idle": "2024-12-31T10:18:06.258042Z",
     "shell.execute_reply": "2024-12-31T10:18:06.257324Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.242382Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['LaBSE',\n",
    "          'mUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.258953Z",
     "iopub.status.busy": "2024-12-31T10:18:06.258754Z",
     "iopub.status.idle": "2024-12-31T10:18:06.269463Z",
     "shell.execute_reply": "2024-12-31T10:18:06.268494Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.258935Z"
    }
   },
   "outputs": [],
   "source": [
    "param_comb = ParameterGrid({'learning_rate' :[1e-1,1e-2],'dropout':[0.2,0.5],'epochs':[5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.270704Z",
     "iopub.status.busy": "2024-12-31T10:18:06.270452Z",
     "iopub.status.idle": "2024-12-31T10:18:06.280726Z",
     "shell.execute_reply": "2024-12-31T10:18:06.279878Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.270682Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "val_metrics = [f1_score]\n",
    "loss = nn.CrossEntropyLoss()\n",
    "sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.284335Z",
     "iopub.status.busy": "2024-12-31T10:18:06.284115Z",
     "iopub.status.idle": "2024-12-31T10:18:06.296643Z",
     "shell.execute_reply": "2024-12-31T10:18:06.295770Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.284315Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_training(models:list,train_df:pd.DataFrame)->list:\n",
    "    '''\n",
    "    Trains the model and get the right hyperparameters for final evaluation.\n",
    "\n",
    "    models\n",
    "    ------\n",
    "        list of embedding libraries to be used in classification\n",
    "    train_df\n",
    "    --------\n",
    "        pandas.DataFrame that stores the training data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        list of the best hyperparameters per model\n",
    "    '''\n",
    "    \n",
    "    best_val_per_model = []\n",
    "    \n",
    "    for m in models:\n",
    "        val_per_model = []\n",
    "        for params in param_comb:\n",
    "            print(str(params))\n",
    "            epochs = params['epochs']\n",
    "            \n",
    "            \n",
    "            tr_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "            \n",
    "            train_ds = CustomDataset(tr_df, m,\"text\", \"label\")\n",
    "            val_ds = CustomDataset(val_df, m,\"text\", \"label\")\n",
    "            train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            model =CustomModel(m,drop_out=params['dropout'])\n",
    "            \n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
    "            scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_dl))\n",
    "            model, val_scores, train_losses, lr_rates = train(model, train_dl, val_dl, loss, optimizer, scheduler, epochs, val_metrics, device,m)\n",
    "            val_per_model.append(val_scores[len(val_scores) -1]['f1_score'])\n",
    "\n",
    "        best_idx = np.argmax(val_per_model)\n",
    "        best_score = (m,param_comb[best_idx])\n",
    "        print(str(best_score))\n",
    "        best_val_per_model.append(best_score)\n",
    "    return best_val_per_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T10:18:06.298439Z",
     "iopub.status.busy": "2024-12-31T10:18:06.298171Z",
     "iopub.status.idle": "2024-12-31T11:04:27.377624Z",
     "shell.execute_reply": "2024-12-31T11:04:27.376671Z",
     "shell.execute_reply.started": "2024-12-31T10:18:06.298419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.2, 'epochs': 5, 'learning_rate': 0.1}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6114206128133705}\n",
      "Loss 0.8918076078097026\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6176880222841226}\n",
      "Loss 0.8099873787826962\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6302228412256268}\n",
      "Loss 0.7699485262235005\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6364902506963789}\n",
      "Loss 0.7289984378549788\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6371866295264624}\n",
      "Loss 0.7051521903938718\n",
      "Done!\n",
      "{'dropout': 0.2, 'epochs': 5, 'learning_rate': 0.01}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6434540389972145}\n",
      "Loss 0.8288327078024547\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.649025069637883}\n",
      "Loss 0.7399081150690715\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6636490250696379}\n",
      "Loss 0.6988914628823598\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6657381615598886}\n",
      "Loss 0.6680390901035733\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6664345403899722}\n",
      "Loss 0.6481077714098824\n",
      "Done!\n",
      "{'dropout': 0.5, 'epochs': 5, 'learning_rate': 0.1}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6002785515320335}\n",
      "Loss 0.9499288982815213\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6232590529247911}\n",
      "Loss 0.8649862580829196\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6030640668523677}\n",
      "Loss 0.8467817578050826\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6364902506963789}\n",
      "Loss 0.7933649394247267\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6344011142061281}\n",
      "Loss 0.7709881914986505\n",
      "Done!\n",
      "{'dropout': 0.5, 'epochs': 5, 'learning_rate': 0.01}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.628133704735376}\n",
      "Loss 0.8574021167225307\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6295264623955432}\n",
      "Loss 0.7596820963753594\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6371866295264624}\n",
      "Loss 0.7369202474753062\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6448467966573816}\n",
      "Loss 0.7045967121918996\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6455431754874652}\n",
      "Loss 0.6906392534573873\n",
      "Done!\n",
      "('LaBSE', {'learning_rate': 0.01, 'epochs': 5, 'dropout': 0.2})\n",
      "{'dropout': 0.2, 'epochs': 5, 'learning_rate': 0.1}\n",
      "Epoch 1/5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-17ebee08b4c6>:42: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  best_score = (m,param_comb[best_idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.584958217270195}\n",
      "Loss 0.9144504368305206\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.5814763231197771}\n",
      "Loss 0.8196359799967872\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6149025069637883}\n",
      "Loss 0.7374294989638859\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6051532033426184}\n",
      "Loss 0.6596722775035434\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6030640668523677}\n",
      "Loss 0.6017037348614799\n",
      "Done!\n",
      "{'dropout': 0.2, 'epochs': 5, 'learning_rate': 0.01}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6337047353760445}\n",
      "Loss 0.8782797118028005\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6344011142061281}\n",
      "Loss 0.7511732498804728\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6274373259052924}\n",
      "Loss 0.6911866698000166\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6371866295264624}\n",
      "Loss 0.6460021515687306\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6392757660167131}\n",
      "Loss 0.6156494713491864\n",
      "Done!\n",
      "{'dropout': 0.5, 'epochs': 5, 'learning_rate': 0.1}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.5327298050139275}\n",
      "Loss 0.9956105477280087\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.5905292479108635}\n",
      "Loss 0.9219811108377245\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6253481894150418}\n",
      "Loss 0.8493055376741622\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6427576601671309}\n",
      "Loss 0.7959625707732306\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6267409470752089}\n",
      "Loss 0.7553488883707259\n",
      "Done!\n",
      "{'dropout': 0.5, 'epochs': 5, 'learning_rate': 0.01}\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.612116991643454}\n",
      "Loss 0.8907587587833404\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6204735376044568}\n",
      "Loss 0.7873050272464752\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6128133704735376}\n",
      "Loss 0.7482337494691212\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6128133704735376}\n",
      "Loss 0.7033200403054555\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "{'f1_score': 0.6149025069637883}\n",
      "Loss 0.687260526087549\n",
      "Done!\n",
      "('mUSE', {'learning_rate': 0.01, 'epochs': 5, 'dropout': 0.2})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-17ebee08b4c6>:42: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  best_score = (m,param_comb[best_idx])\n"
     ]
    }
   ],
   "source": [
    "best_val_per_model = perform_training(models, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:04:27.379056Z",
     "iopub.status.busy": "2024-12-31T11:04:27.378734Z",
     "iopub.status.idle": "2024-12-31T11:04:27.385378Z",
     "shell.execute_reply": "2024-12-31T11:04:27.384420Z",
     "shell.execute_reply.started": "2024-12-31T11:04:27.379030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LaBSE', {'learning_rate': 0.01, 'epochs': 5, 'dropout': 0.2}),\n",
       " ('mUSE', {'learning_rate': 0.01, 'epochs': 5, 'dropout': 0.2})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:04:27.386596Z",
     "iopub.status.busy": "2024-12-31T11:04:27.386294Z",
     "iopub.status.idle": "2024-12-31T11:04:27.397789Z",
     "shell.execute_reply": "2024-12-31T11:04:27.396962Z",
     "shell.execute_reply.started": "2024-12-31T11:04:27.386552Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_testing(best_val_per_model:list,train_df:pd.DataFrame,test_df:pd.DataFrame)->list:\n",
    "    '''\n",
    "    Test the model with their best hyperparametes.\n",
    "\n",
    "    best_val_per_model\n",
    "    ------------------\n",
    "        list that stores the best hyperparameters per library\n",
    "    train_df\n",
    "    --------\n",
    "        pandas.DataFrame that stores the training data\n",
    "\n",
    "    test_df\n",
    "    --------\n",
    "        pandas.DataFrame that stores the training data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame of result f1 score per epoch\n",
    "        list of tuples which stores all predictions for each model\n",
    "    '''\n",
    "    \n",
    "    res_df = pd.DataFrame(columns=['model', 'f1_score'])\n",
    "    compar = []\n",
    "    for val in best_val_per_model:\n",
    "        res = []\n",
    "        params = val[1]\n",
    "        m = val[0]\n",
    "        res.append(m)\n",
    "        epochs = params['epochs']\n",
    "        \n",
    "        train_ds = CustomDataset(train_df, m,\"text\", \"label\")\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model =CustomModel(m,drop_out=params['dropout'])\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
    "        \n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_dl))\n",
    "        loaded_model = train_only(model, train_dl,loss, optimizer, scheduler, epochs, val_metrics, device,m)\n",
    "        torch.save(model.state_dict(), 'model_weights.pth')\n",
    "        \n",
    "        \n",
    "        test_ds = CustomDataset(test_df,m,\"text\", \"label\")\n",
    "        test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "        loaded_model.eval()\n",
    "        preds = predict(loaded_model, test_dl,device,m )\n",
    "\n",
    "\n",
    "        model_f1_sc = f1_score(test_df['label'], preds, average='macro')\n",
    "        res.append(model_f1_sc)\n",
    "        \n",
    "        res_df.loc[len(res_df)] = res\n",
    "        compar.append((m,test_df['label'],preds))\n",
    "    res_df = res_df.set_index('model')\n",
    "    return res_df,compar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:04:27.398980Z",
     "iopub.status.busy": "2024-12-31T11:04:27.398638Z",
     "iopub.status.idle": "2024-12-31T11:16:42.009495Z",
     "shell.execute_reply": "2024-12-31T11:16:42.008714Z",
     "shell.execute_reply.started": "2024-12-31T11:04:27.398941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "-------------------------------\n",
      "Loss 0.8156385136916574\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "Loss 0.7251854544192289\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "Loss 0.6940368477222139\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "Loss 0.6564069640847434\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "Loss 0.6385601811704382\n",
      "Done!\n",
      "Epoch 1/5\n",
      "-------------------------------\n",
      "Loss 0.8644441176304775\n",
      "Epoch 2/5\n",
      "-------------------------------\n",
      "Loss 0.7589691059779277\n",
      "Epoch 3/5\n",
      "-------------------------------\n",
      "Loss 0.7027081361914103\n",
      "Epoch 4/5\n",
      "-------------------------------\n",
      "Loss 0.6559503416044522\n",
      "Epoch 5/5\n",
      "-------------------------------\n",
      "Loss 0.6285838033773202\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "res_df,model_compar = perform_testing(best_val_per_model,train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.010717Z",
     "iopub.status.busy": "2024-12-31T11:16:42.010343Z",
     "iopub.status.idle": "2024-12-31T11:16:42.018751Z",
     "shell.execute_reply": "2024-12-31T11:16:42.017642Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.010670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       f1_score\n",
      "model          \n",
      "LaBSE  0.645179\n",
      "mUSE   0.601181\n"
     ]
    }
   ],
   "source": [
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.019987Z",
     "iopub.status.busy": "2024-12-31T11:16:42.019722Z",
     "iopub.status.idle": "2024-12-31T11:16:42.026333Z",
     "shell.execute_reply": "2024-12-31T11:16:42.025547Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.019966Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_short(x:float):\n",
    "    '''\n",
    "    Shortens float value to two decimal places\n",
    "    '''\n",
    "    return f\"{x:.2f}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.027248Z",
     "iopub.status.busy": "2024-12-31T11:16:42.027021Z",
     "iopub.status.idle": "2024-12-31T11:16:42.041748Z",
     "shell.execute_reply": "2024-12-31T11:16:42.041045Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.027228Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_res(latex_table:str,name)->None:\n",
    "    '''\n",
    "    Saves the results to latex table\n",
    "    latex_table\n",
    "    -----------\n",
    "        string that defines created latex table\n",
    "    name\n",
    "    ----\n",
    "        string that defines the name of the file\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    with open(name+ '.txt','w+') as f:\n",
    "        f.write(latex_table)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.042677Z",
     "iopub.status.busy": "2024-12-31T11:16:42.042436Z",
     "iopub.status.idle": "2024-12-31T11:16:42.128188Z",
     "shell.execute_reply": "2024-12-31T11:16:42.127302Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.042656Z"
    }
   },
   "outputs": [],
   "source": [
    "latex_table = res_df.style.format({\n",
    "        \"f1_score\": to_short,\n",
    "        }).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.129711Z",
     "iopub.status.busy": "2024-12-31T11:16:42.129104Z",
     "iopub.status.idle": "2024-12-31T11:16:42.135499Z",
     "shell.execute_reply": "2024-12-31T11:16:42.134833Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.129673Z"
    }
   },
   "outputs": [],
   "source": [
    "latex_table = res_df.style.format({\n",
    "        \"f1_score\": to_short,\n",
    "        }).to_latex()\n",
    "latex_table = latex_table.replace('{lr}', '{l||c}')\n",
    "latex_table = latex_table.replace('model &  \\\\\\\\', '\\\\hline')\n",
    "latex_table = latex_table.replace('f1_score', 'f1 score')\n",
    "latex_table = latex_table.replace(' & f1 score','model & f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.136792Z",
     "iopub.status.busy": "2024-12-31T11:16:42.136428Z",
     "iopub.status.idle": "2024-12-31T11:16:42.147223Z",
     "shell.execute_reply": "2024-12-31T11:16:42.146428Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.136739Z"
    }
   },
   "outputs": [],
   "source": [
    "save_res(latex_table,'final_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.148285Z",
     "iopub.status.busy": "2024-12-31T11:16:42.147985Z",
     "iopub.status.idle": "2024-12-31T11:16:42.161748Z",
     "shell.execute_reply": "2024-12-31T11:16:42.160946Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.148251Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_class_charts(model_compar:list,df:pd.DataFrame)->None:\n",
    "    '''\n",
    "    Plots graph of distribution of languages of incorrectly classified texts.\n",
    "\n",
    "    model_compar\n",
    "    ------------\n",
    "        list of predictions and correct data per model\n",
    "    df\n",
    "    --------\n",
    "        pd.DataFrame The original dataset\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    '''\n",
    "    for mc in model_compar:\n",
    "        indexes = []\n",
    "        for idx,p in enumerate(mc[1].values):\n",
    "            if p != mc[2][idx]:\n",
    "                indexes.append(mc[1].index[idx])\n",
    "        new_df = df.loc[indexes]\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        new_df['language'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colormap='Pastel1')\n",
    "\n",
    "        plt.title('Incorrectly classified texts with ' + str(mc[0]))\n",
    "        plt.ylabel('')  \n",
    "        #plt.show()\n",
    "        plt.savefig(str(mc[0]) + \".jpg\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T11:16:42.162716Z",
     "iopub.status.busy": "2024-12-31T11:16:42.162475Z",
     "iopub.status.idle": "2024-12-31T11:16:42.353254Z",
     "shell.execute_reply": "2024-12-31T11:16:42.352548Z",
     "shell.execute_reply.started": "2024-12-31T11:16:42.162697Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_class_charts(model_compar,df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6399696,
     "sourceId": 10335389,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 129,
     "modelInstanceId": 981,
     "sourceId": 1135,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 191,
     "modelInstanceId": 1283,
     "sourceId": 1523,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 191,
     "modelInstanceId": 1286,
     "sourceId": 1527,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
